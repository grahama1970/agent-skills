"""
Paper Writer Skill - Compliance
Disclosure generation, sanitization, venue policy compliance.
"""
import json
import re
from pathlib import Path
from typing import Any, Dict, List

import typer

from citations import check_citations
from config import VENUE_POLICIES
from utils import get_ai_usage_ledger, sanitize_prompt_injection


def generate_disclosure(venue: str) -> Dict[str, str]:
    """Generate LLM-use disclosure statement for target venue.

    Args:
        venue: Target venue key

    Returns:
        Dict with disclosure text and location
    """
    venue_key = venue.lower()
    policy = VENUE_POLICIES.get(venue_key, VENUE_POLICIES["arxiv"])

    latex_content = f"""% LLM Disclosure Statement for {policy['name']}
% Location: {policy['disclosure_location']}
% Generated by create-paper skill

{policy['disclosure_template']}
"""

    return {
        "venue": policy["name"],
        "location": policy["disclosure_location"],
        "text": policy["disclosure_template"],
        "latex": latex_content,
        "policy_notes": policy.get("policy_notes", []),
    }


def generate_ai_ledger_disclosure(paper_dir: Path) -> Dict[str, Any]:
    """Generate disclosure from AI usage ledger.

    Args:
        paper_dir: Path to paper directory

    Returns:
        Disclosure data dict
    """
    ledger_file = paper_dir / "ai_usage_ledger.json"

    if not ledger_file.exists():
        return {"error": "No AI usage ledger found"}

    ledger_data = json.loads(ledger_file.read_text())
    entries = ledger_data.get("entries", [])

    # Aggregate usage
    tools_used = set(e.get("tool_name", "") for e in entries)
    purposes = set(e.get("purpose", "") for e in entries)
    sections = set(e.get("section_affected", "") for e in entries)

    disclosure = f"""% AI Usage Disclosure (ICLR 2026 Compliant)
% Generated from AI usage ledger with {len(entries)} logged operations

This paper was prepared with AI writing assistance. The following AI tools
were used during the writing process:

Tools: {', '.join(sorted(tools_used))}
Purposes: {', '.join(sorted(purposes))}
Sections affected: {', '.join(sorted(sections))}

The authors take full responsibility for the accuracy, originality, and
integrity of all content. All claims have been verified against primary
sources, and all citations have been validated for existence and relevance.
"""

    return {
        "total_uses": len(entries),
        "tools": list(tools_used),
        "purposes": list(purposes),
        "sections": list(sections),
        "disclosure_text": disclosure,
    }


def run_pre_submit_checks(
    paper_dir: Path,
    venue: str = "arxiv",
    project_path: Path = None,
) -> Dict[str, Any]:
    """Run pre-submission checklist and validation.

    Args:
        paper_dir: Path to paper directory
        venue: Target venue
        project_path: Optional project path for evidence grounding

    Returns:
        Results dict with checks and critical failures
    """
    checks = []
    critical_fails = []
    sections_dir = paper_dir / "sections"

    # === CHECK 1: File Structure ===
    required_files = ["draft.tex"]
    optional_files = ["references.bib", "abstract.tex"]

    for req in required_files:
        if (paper_dir / req).exists():
            checks.append(("pass", f"Required file: {req}"))
        else:
            checks.append(("fail", f"Missing required: {req}"))
            critical_fails.append(f"Missing {req}")

    for opt in optional_files:
        if (paper_dir / opt).exists():
            checks.append(("pass", f"Optional file: {opt}"))
        else:
            checks.append(("info", f"Optional missing: {opt}"))

    # === CHECK 2: Sections ===
    required_sections = ["intro", "method", "eval", "conclusion"]
    recommended_sections = ["related", "abstract"]

    if sections_dir.exists():
        existing = [f.stem for f in sections_dir.glob("*.tex")]

        for sec in required_sections:
            if sec in existing:
                checks.append(("pass", f"Required section: {sec}"))
            else:
                checks.append(("fail", f"Missing required section: {sec}"))
                critical_fails.append(f"Missing section: {sec}")

        for sec in recommended_sections:
            if sec in existing:
                checks.append(("pass", f"Recommended section: {sec}"))
            else:
                checks.append(("info", f"Recommended missing: {sec}"))

        if "limitations" in existing or "discussion" in existing:
            checks.append(("pass", "Limitations/Discussion section present"))
        else:
            checks.append(("warn", "No explicit limitations section"))
    else:
        checks.append(("fail", "No sections directory found"))
        critical_fails.append("No sections directory")

    # === CHECK 3: Citations ===
    tex_files = list(paper_dir.rglob("*.tex"))
    bib_files = list(paper_dir.rglob("*.bib"))

    all_cites = set()
    bib_entries = set()

    for tf in tex_files:
        content = tf.read_text()
        matches = re.findall(r"\\cite[pt]?\{([^}]+)\}", content)
        for m in matches:
            all_cites.update(c.strip() for c in m.split(","))

    for bf in bib_files:
        content = bf.read_text()
        matches = re.findall(r"@\w+\{([^,]+),", content)
        bib_entries.update(m.strip() for m in matches)

    missing_cites = all_cites - bib_entries
    if missing_cites:
        checks.append(("fail", f"Missing .bib entries: {len(missing_cites)}"))
        critical_fails.append(f"Missing citations: {', '.join(list(missing_cites)[:3])}")
    else:
        checks.append(("pass", f"All {len(all_cites)} citations have .bib entries"))

    # === CHECK 4: LLM Disclosure ===
    venue_policy = VENUE_POLICIES.get(venue.lower(), VENUE_POLICIES["arxiv"])

    disclosure_found = False
    for tf in tex_files:
        content = tf.read_text().lower()
        if any(term in content for term in ["ai assistance", "llm", "language model", "ai writing"]):
            disclosure_found = True
            break

    if disclosure_found:
        checks.append(("pass", f"LLM disclosure statement found ({venue_policy['name']} compliant)"))
    else:
        if venue_policy["disclosure_required"]:
            checks.append(("warn", f"No LLM disclosure found (required for {venue_policy['name']})"))
        else:
            checks.append(("info", "No LLM disclosure (not strictly required)"))

    # === CHECK 5: Evidence Grounding ===
    if project_path:
        if project_path.exists():
            checks.append(("pass", f"Project path valid: {project_path.name}"))

            code_refs = 0
            for tf in tex_files:
                content = tf.read_text()
                if "listing" in content.lower() or "algorithm" in content.lower():
                    code_refs += 1
                if "figure" in content.lower() or "table" in content.lower():
                    code_refs += 1

            if code_refs > 0:
                checks.append(("pass", f"Found {code_refs} code/figure references"))
            else:
                checks.append(("warn", "No code listings or algorithm references found"))
        else:
            checks.append(("warn", f"Project path not found: {project_path}"))
    else:
        checks.append(("info", "No project specified for grounding check"))

    return {
        "checks": checks,
        "critical_fails": critical_fails,
        "venue": venue_policy["name"],
        "passed": len(critical_fails) == 0,
    }


def sanitize_paper(paper_dir: Path, fix: bool = False) -> Dict[str, Any]:
    """Sanitize paper for prompt injection attacks.

    Args:
        paper_dir: Path to paper directory
        fix: If True, auto-fix detected issues

    Returns:
        Results dict with warnings and fixes
    """
    all_warnings: List[tuple[str, List[str]]] = []
    files_checked = 0
    files_fixed = 0

    for tex_file in paper_dir.rglob("*.tex"):
        files_checked += 1
        content = tex_file.read_text()
        sanitized, warnings = sanitize_prompt_injection(content)

        if warnings:
            rel_path = str(tex_file.relative_to(paper_dir))
            all_warnings.append((rel_path, warnings))

            if fix:
                tex_file.write_text(sanitized)
                files_fixed += 1

    return {
        "files_checked": files_checked,
        "files_with_issues": len(all_warnings),
        "total_issues": sum(len(w) for _, w in all_warnings),
        "files_fixed": files_fixed,
        "warnings": all_warnings,
        "clean": len(all_warnings) == 0,
    }


def get_venue_policy(venue: str) -> Dict[str, Any]:
    """Get venue policy details.

    Args:
        venue: Venue key

    Returns:
        Policy dict
    """
    return VENUE_POLICIES.get(venue.lower(), VENUE_POLICIES["arxiv"])


def list_venues() -> List[str]:
    """List available venue keys.

    Returns:
        List of venue keys
    """
    return list(VENUE_POLICIES.keys())
