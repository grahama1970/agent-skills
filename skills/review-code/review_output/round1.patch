Hardening: concurrency, state, UA, packaging, and doctor exit

diff --git a/.pi/skills/consume-feed/cli.py b/.pi/skills/consume-feed/cli.py
index 6b9f7a4..3e7f3f2 100644
--- a/.pi/skills/consume-feed/cli.py
+++ b/.pi/skills/consume-feed/cli.py
@@ -44,7 +44,7 @@ def doctor():
     try:
         storage = FeedStorage()
         console.print(f"[green]✓ ArangoDB connected ('{storage.db_name}')[/green]")
     except Exception as e:
         console.print(f"[red]✗ ArangoDB error: {e}[/red]")
-        # Don't exit, might be transient network issue
+        sys.exit(1)

diff --git a/.pi/skills/consume-feed/sources/base.py b/.pi/skills/consume-feed/sources/base.py
index f4a4f3e..6e7f9c2 100644
--- a/.pi/skills/consume-feed/sources/base.py
+++ b/.pi/skills/consume-feed/sources/base.py
@@ -13,11 +13,12 @@ class SourceStats(BaseModel):
     status: str = "ok" # ok, failed, skipped
 
 class BaseSource(ABC):
-    def __init__(self, config: FeedSource, storage: FeedStorage):
+    def __init__(self, config: FeedSource, storage: FeedStorage, user_agent: str | None = None):
         self.config = config
         self.storage = storage
         self.key = config.key
         self.logger_name = f"source.{self.key}"
+        self.user_agent = user_agent or "ConsumeFeed/1.0"
 
     @abstractmethod
     def fetch(self) -> SourceStats:

diff --git a/.pi/skills/consume-feed/runner.py b/.pi/skills/consume-feed/runner.py
index e7b0b5a..8b0c2f3 100644
--- a/.pi/skills/consume-feed/runner.py
+++ b/.pi/skills/consume-feed/runner.py
@@ -21,6 +21,8 @@ class FeedRunner:
         self.storage = FeedStorage(
             url=config.arango_url, 
             db_name=config.arango_db
         )
+        # Respect configured User-Agent for network calls
+        self.user_agent = config.run_options.user_agent
 
     def _get_source_instance(self, source_config: FeedSource):
         """Factory method to instantiate the correct source class."""
@@ -28,7 +30,7 @@ class FeedRunner:
         # This will need to be expanded as we implement sources
         if source_config.type == SourceType.RSS:
-            return RSSSource(source_config, self.storage)
+            return RSSSource(source_config, self.storage, user_agent=self.user_agent)
         # elif source_config.type == SourceType.GITHUB:
         #     return GitHubReleasesSource(source_config, self.storage)
         # elif source_config.type == SourceType.NVD:
         #     return NVDSource(source_config, self.storage)

diff --git a/.pi/skills/consume-feed/sources/rss.py b/.pi/skills/consume-feed/sources/rss.py
index 2f0d0e3..7f9a1c1 100644
--- a/.pi/skills/consume-feed/sources/rss.py
+++ b/.pi/skills/consume-feed/sources/rss.py
@@ -20,23 +20,28 @@ class RSSSource(BaseSource):
         last_modified = state.get("last_modified")
         
         # 2. Fetch
-        with HttpClient(user_agent=self.storage.db.name if False else "ConsumeFeed/1.0") as client:
+        with HttpClient(user_agent=self.user_agent) as client:
             try:
                 status, text, headers = client.fetch_text(
                     self.config.rss_url,
                     etag=etag,
                     last_modified=last_modified
                 )
             except Exception as e:
-                # Check if it was a 304 handled by exception? 
-                # (No, HttpClient returns 304 status, doesn't raise unless error)
-                # If we are here, it's a real error (timeout, 500, etc) inherited from tenacity
                 stats.errors += 1
                 stats.status = "failed"
                 console.print(f"[red]Fetch failed for {self.key}: {e}[/red]")
                 return stats
 
         if status == 304:
             console.print(f"[dim]No changes for {self.key} (304 Not Modified)[/dim]")
             stats.status = "skipped_304"
+            # Persist last_fetch_at even if not modified to reflect polling
+            if not dry_run:
+                self.save_state({
+                    "etag": etag,
+                    "last_modified": last_modified,
+                    "last_fetch_at": time.time()
+                })
             return stats
 
         # 3. Parse
@@ -106,7 +111,7 @@ class RSSSource(BaseSource):
 
         # 4. Upsert
         if not dry_run and items_to_upsert:
-            writes = self.storage.upsert_items(items_to_upsert)
+            writes = self.storage.upsert_items(items_to_upsert)
             stats.upserted_count = writes
         elif dry_run:
             console.print(f"[dim]Dry run: would upsert {len(items_to_upsert)} items[/dim]")
@@ -114,10 +119,10 @@ class RSSSource(BaseSource):
         # 5. Save State
         if not dry_run:
             new_state = {
-                "etag": headers.get("ETag"),
-                "last_modified": headers.get("Last-Modified"),
+                "etag": headers.get("ETag"),
+                "last_modified": headers.get("Last-Modified"),
                 "last_fetch_at": time.time(),
-                "last_success_at": time.time()
+                "last_success_at": time.time()
             }
             self.save_state(new_state)
 
diff --git a/.pi/skills/consume-feed/util/http.py b/.pi/skills/consume-feed/util/http.py
index 8b3a2f1..f5b7b9a 100644
--- a/.pi/skills/consume-feed/util/http.py
+++ b/.pi/skills/consume-feed/util/http.py
@@ -30,7 +30,21 @@ RETRY_CONFIG = dict(
 class HttpClient:
-    def __init__(self, user_agent: str = "ConsumeFeed/1.0"):
-        self.headers = {"User-Agent": user_agent}
-        self.client = httpx.Client(timeout=30.0)
+    def __init__(self, user_agent: str = "ConsumeFeed/1.0", timeout: float = 30.0):
+        self.headers = {"User-Agent": user_agent}
+        self.client = httpx.Client(timeout=timeout)
+
+    def close(self):
+        try:
+            self.client.close()
+        except Exception:
+            pass
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, exc_type, exc, tb):
+        self.close()
 
     @retry(**RETRY_CONFIG)
     def fetch_text(self, url: str, etag: Optional[str] = None, last_modified: Optional[str] = None) -> tuple[int, str, Dict[str, str]]:
diff --git a/.pi/skills/consume-feed/storage.py b/.pi/skills/consume-feed/storage.py
index 5b5f4b9..1b2f3f1 100644
--- a/.pi/skills/consume-feed/storage.py
+++ b/.pi/skills/consume-feed/storage.py
@@ -1,7 +1,8 @@
 import sys
 import os
 import time
-from typing import Dict, Any, List, Optional
+import threading
+from typing import Dict, Any, List, Optional
 from rich.console import Console
 
 # Add memory skill to path to import connection logic
@@ -48,7 +49,8 @@ class FeedStorage:
             self.db = self.client.db(db_name, username="root", password="")
             self.db_name = db_name
 
-        self._init_schema()
+        self._lock = threading.Lock()
+        self._init_schema()
 
     def _init_schema(self):
         """Ensure collections and views exist (Idempotent)."""
@@ -93,23 +95,27 @@ class FeedStorage:
     def upsert_items(self, items: List[Dict[str, Any]]) -> int:
         if not items:
             return 0
         col = self.db.collection("feed_items")
-        result = col.import_bulk(items, on_duplicate="update", halt_on_error=False)
-        return result["created"] + result["updated"]
+        with self._lock:
+            result = col.import_bulk(items, on_duplicate="update", halt_on_error=False)
+        created = int(result.get("created", 0))
+        updated = int(result.get("updated", 0))
+        return created + updated
 
     def get_state(self, source_key: str) -> Dict[str, Any]:
         col = self.db.collection("feed_state")
         if col.has(source_key):
             return col.get(source_key)
         return {"_key": source_key}
 
     def save_state(self, source_key: str, state: Dict[str, Any]):
         state["_key"] = source_key
         state["updated_at"] = time.time()
-        self.db.collection("feed_state").insert(state, overwrite=True, silent=True)
+        with self._lock:
+            self.db.collection("feed_state").insert(state, overwrite=True, silent=True)
 
     def log_deadletter(self, doc: Dict[str, Any]):
         doc["logged_at"] = time.time()
-        self.db.collection("feed_deadletters").insert(doc, silent=True)
+        with self._lock:
+            self.db.collection("feed_deadletters").insert(doc, silent=True)
         
     def log_run(self, run_stats: Dict[str, Any]):
         run_stats["logged_at"] = time.time()
-        self.db.collection("feed_runs").insert(run_stats, silent=True)
+        with self._lock:
+            self.db.collection("feed_runs").insert(run_stats, silent=True)

diff --git a/.pi/skills/consume-feed/storage.py b/.pi/skills/consume-feed/storage.py
index 1b2f3f1..a3c2f17 100644
--- a/.pi/skills/consume-feed/storage.py
+++ b/.pi/skills/consume-feed/storage.py
@@ -13,9 +13,9 @@ if MEMORY_SKILL_PATH not in sys.path:
     sys.path.append(MEMORY_SKILL_PATH)
 
 try:
     from horus_lore_storage import get_db
-except ImportError:
-    # Fallback if memory skill is missing (e.g. standalone dev)
-    # But for this environment, we expect it.
+except ImportError:
+    # Hard fail to avoid bespoke wrappers; this skill must reuse Memory's connection.
     from arango import ArangoClient
-    def get_db():
-        url = os.getenv("ARANGO_URL", "http://127.0.0.1:8529")
-        db_name = os.getenv("ARANGO_DB", "feed_db")
-        # In standalone, we might default differently, but let's stick to env
-        client = ArangoClient(hosts=url)
-        # Note: horus_lore_storage uses 'memory' db by default.
-        # We want to support that reused connection.
-        return client.db(db_name, username=os.getenv("ARANGO_USER", "root"), password=os.getenv("ARANGO_PASS", ""))
+    raise ImportError("Memory skill connection 'get_db' not available. Ensure Memory skill is installed and on PYTHONPATH.")

diff --git a/.pi/skills/consume-feed/pyproject.toml b/.pi/skills/consume-feed/pyproject.toml
index 1a2b3c4..e3d4f5a 100644
--- a/.pi/skills/consume-feed/pyproject.toml
+++ b/.pi/skills/consume-feed/pyproject.toml
@@ -21,23 +21,6 @@ build-backend = "hatchling.build"
 
-[tool.hatch.build.targets.wheel]
-packages = ["sources", "util"]
-# We also need to include the top-level modules. 
-# Hatchling is strict about "packages" meaning directories.
-# To support flat layout with top-level modules, we usually rely on 'force-include'.
-
-[tool.hatch.build.targets.wheel.force-include]
-"cli.py" = "consume_feed/cli.py"
-"config.py" = "consume_feed/config.py"
-"runner.py" = "consume_feed/runner.py"
-"storage.py" = "consume_feed/storage.py"
-"sources" = "consume_feed/sources"
-"util" = "consume_feed/util"
-
-# Wait, the above effectively moves them into a package named 'consume_feed' in the wheel.
-# This actually solves the import problem nicely (local code runs flat, installed code runs as package).
-# BUT, `python -m cli` in the `run.sh` relies on them being in the CWD/root.
-# `uv run` installs the project in editable mode.
-# If we use editable mode, hatch needs to know where the source is.
+[tool.hatch.build.targets.wheel]
+packages = []
 # Internal skill; no packaging remaps or force-includes needed.
 
 [tool.hatch.build.targets.sdist]