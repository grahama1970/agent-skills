{
  "_comment": "Models available on Chutes.ai - includes parameter sizes, quantization, and capabilities",
  "_updated": "2026-01-28",
  "_schema": {
    "params_b": "Total parameters in billions",
    "active_params_b": "Active parameters for MoE models",
    "quantization": "FP16, BF16, FP8, INT8, INT4, AWQ, GPTQ, etc.",
    "context_k": "Context length in thousands of tokens",
    "architecture": "Dense or MoE",
    "experts": "Number of experts for MoE models",
    "experts_active": "Number of active experts per token",
    "json_mode": "Whether JSON output mode works reliably",
    "reasoning": "Extended reasoning/thinking capability",
    "thinking_mode": "Supports thinking mode toggle",
    "agentic": "Optimized for tool use and agents",
    "coding": "Specialized for code generation"
  },

  "deepseek-v3": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-V3-0324-TEE",
    "params_b": 671,
    "active_params_b": 37,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "taxonomy_f1": 0.95,
    "notes": "Original V3, proven for taxonomy"
  },
  "deepseek-v3.1": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-V3.1-TEE",
    "params_b": 671,
    "active_params_b": 37,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "thinking_mode": true,
    "notes": "V3.1 with thinking modes"
  },
  "deepseek-v3.2": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-V3.2-TEE",
    "params_b": 671,
    "active_params_b": 37,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "thinking_mode": true,
    "notes": "Latest V3.2"
  },
  "deepseek-v3.2-speciale": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-V3.2-Speciale-TEE",
    "params_b": 671,
    "active_params_b": 37,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "notes": "V3.2 Speciale variant"
  },
  "deepseek-terminus": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-V3.1-Terminus-TEE",
    "params_b": 671,
    "active_params_b": 37,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "thinking_mode": true,
    "agentic": true,
    "notes": "V3.1 Terminus - optimized for reasoning, coding, agentic tool use"
  },
  "deepseek-r1": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-R1-TEE",
    "params_b": 671,
    "active_params_b": 37,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "reasoning": true,
    "notes": "R1 reasoning model"
  },
  "deepseek-r1-0528": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-R1-0528-TEE",
    "params_b": 671,
    "active_params_b": 37,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "reasoning": true,
    "notes": "R1 May 2028 release"
  },

  "qwen3-235b": {
    "provider": "chutes",
    "model": "Qwen/Qwen3-235B-A22B-Instruct-2507-TEE",
    "params_b": 235,
    "active_params_b": 22,
    "quantization": "BF16",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 128,
    "experts_active": 8,
    "json_mode": true,
    "notes": "Qwen3 235B MoE"
  },
  "qwen3-coder-480b": {
    "provider": "chutes",
    "model": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE",
    "params_b": 480,
    "active_params_b": 35,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 128,
    "experts_active": 8,
    "json_mode": true,
    "coding": true,
    "notes": "Qwen3 Coder 480B - largest Qwen, FP8 quantized"
  },
  "qwen2.5-72b": {
    "provider": "chutes",
    "model": "Qwen/Qwen2.5-72B-Instruct",
    "params_b": 72,
    "quantization": "BF16",
    "context_k": 128,
    "architecture": "Dense",
    "json_mode": true,
    "notes": "Qwen 2.5 72B dense"
  },
  "qwen3-32b": {
    "provider": "chutes",
    "model": "Qwen/Qwen3-32B",
    "params_b": 32,
    "quantization": "BF16",
    "context_k": 128,
    "architecture": "Dense",
    "json_mode": true,
    "notes": "Qwen3 32B dense"
  },

  "kimi": {
    "provider": "chutes",
    "model": "moonshotai/Kimi-K2.5-TEE",
    "params_b": 1000,
    "active_params_b": 32,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": false,
    "notes": "Kimi K2.5 - FAILS JSON mode, use kimi-instruct instead"
  },
  "kimi-thinking": {
    "provider": "chutes",
    "model": "moonshotai/Kimi-K2-Thinking-TEE",
    "params_b": 1000,
    "active_params_b": 32,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "reasoning": true,
    "notes": "Kimi K2 Thinking - reasoning variant"
  },
  "kimi-instruct": {
    "provider": "chutes",
    "model": "moonshotai/Kimi-K2-Instruct-0905",
    "params_b": 1000,
    "active_params_b": 32,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "MoE",
    "experts": 256,
    "experts_active": 8,
    "json_mode": true,
    "notes": "Kimi K2 Instruct - September 2025, reliable JSON"
  },

  "hermes-405b": {
    "provider": "chutes",
    "model": "NousResearch/Hermes-4-405B-FP8-TEE",
    "params_b": 405,
    "quantization": "FP8",
    "context_k": 128,
    "architecture": "Dense",
    "json_mode": true,
    "notes": "Hermes 4 405B dense (Llama 3.1 base), FP8 quantized"
  },
  "hermes-70b": {
    "provider": "chutes",
    "model": "NousResearch/Hermes-4-70B",
    "params_b": 70,
    "quantization": "BF16",
    "context_k": 128,
    "architecture": "Dense",
    "json_mode": true,
    "notes": "Hermes 4 70B dense"
  },

  "glm-4.7": {
    "provider": "chutes",
    "model": "zai-org/GLM-4.7-TEE",
    "params_b": 9,
    "quantization": "BF16",
    "context_k": 128,
    "architecture": "Dense",
    "json_mode": true,
    "notes": "GLM 4.7 - efficient small model"
  },
  "minimax": {
    "provider": "chutes",
    "model": "MiniMaxAI/MiniMax-M2.1-TEE",
    "params_b": 456,
    "active_params_b": 45.9,
    "quantization": "FP8",
    "context_k": 1000,
    "architecture": "MoE",
    "experts": 32,
    "experts_active": 2,
    "json_mode": true,
    "notes": "MiniMax M2.1 - 1M context, lightning MoE"
  },

  "deepseek": {
    "provider": "chutes",
    "model": "deepseek-ai/DeepSeek-V3-0324-TEE",
    "notes": "Default alias for deepseek-v3"
  }
}
